	////matrix test
	//float a[12];// 4 x 3
	//for (int i = 0; i < 12; i++) {
	//	a[i] = i + 1;
	//}

	//float b[15];// 3 x 5
	//for (int i = 0; i < 15; i++) {
	//	b[i] = i + 1;
	//}

	//float c[20];

	//float* adev;
	//float* bdev;
	//float* cdev;

	//cudaMalloc((void**)&adev, 12 * sizeof(float));
	//cudaMemcpy(adev, a, 12 * sizeof(float), cudaMemcpyHostToDevice);
	//cudaMalloc((void**)&bdev, 15 * sizeof(float));
	//cudaMemcpy(bdev, b, 15 * sizeof(float), cudaMemcpyHostToDevice);
	//cudaMalloc((void**)&cdev, 20 * sizeof(float));

	//matrix_multiplication << <4, 5 >> > (adev, 4, 3, bdev, 3, 5, cdev);
	//cudaMemcpy(c, cdev, 20 * sizeof(float), cudaMemcpyDeviceToHost);
	//cout << cudaGetErrorString(cudaGetLastError()) << endl;
	//for (int i = 0; i < 20; i++) {
	//	cout << c[i] << ' ';
	//}
	//cout << endl;
	//return 0;
	
	//transpose test
	float a[12];// 4 x 3
	float at[12];
	for (int i = 0; i < 12; i++) {
		a[i] = i + 1;
	}	

	float* adev;
	float* atdev;

	cudaMalloc((void**)&adev, 12 * sizeof(float));
	cudaMemcpy(adev, a, 12 * sizeof(float), cudaMemcpyHostToDevice);
	cudaMalloc((void**)&atdev, 12 * sizeof(float));

	matrix_transpose << <4, 3 >> > (adev, 4, 3, atdev);	
	cout << cudaGetErrorString(cudaGetLastError()) << endl;
	cudaMemcpy(at, atdev, 12 * sizeof(float), cudaMemcpyDeviceToHost);
	for (int i = 0; i < 12; i++) {
		cout << at[i] << ' ';		
	}
	cout << endl;
	return 0;
	
	
	
	cudaMemcpy(levels[0], image, INPUT_SIZE * sizeof(float), cudaMemcpyHostToDevice);

	matrix_multiplication << <1, ws_w_sz[0] >> > (levels[0], 1, INPUT_SIZE, wss_dev[0], ws_h_sz[0], ws_w_sz[0], levels[1]);
	bias_sigmoid << <1, ws_w_sz[0] >> > (levels[1], bss_dev[0]);

	matrix_multiplication << <1, ws_w_sz[1] >> > (levels[1], 1, ws_w_sz[0], wss_dev[1], ws_h_sz[1], ws_w_sz[1], levels[2]);
	bias_sigmoid << <1, ws_w_sz[1] >> > (levels[2], bss_dev[1]);

	matrix_multiplication << <1, ws_w_sz[2] >> > (levels[2], 1, ws_w_sz[1], wss_dev[2], ws_h_sz[2], ws_w_sz[2], levels[3]);
	bias_sigmoid << <1, ws_w_sz[2] >> > (levels[3], bss_dev[2]);

	softmax << <1, 1 >> > (levels[2], output_dev, ws_w_sz[2]);
	cudaMemcpy(output, output_dev, ws_w_sz[2] * sizeof(float), cudaMemcpyDeviceToHost);
	
	
	
	predict(img, label);

	output[label]--;
	cudaMemcpy(swl, output, 10 * sizeof(float), cudaMemcpyHostToDevice);
	output[label]++;

	matrix_multiplication << <1, ws_h_sz[2] >> > (swl, 1, ws_w_sz[2], wsst[2], ws_w_sz[2], ws_h_sz[2], xssd[2]); //xssd[2] = 1 x 100
	matrix_multiplication << <ws_w_sz[1], ws_w_sz[2] >> > (levels[2], ws_w_sz[1], 1, swl, 1, ws_w_sz[2], wssd[2]); // wssd[2] = 100 x 10
	sigmoid_backward << <1, ws_w_sz[2] >> > (xssd[2], levels[2], 1, ws_w_sz[1]);

	matrix_multiplication << <1, ws_h_sz[2] >> > (xssd[2], 1, ws_w_sz[1], wsst[1], ws_w_sz[1], ws_h_sz[1], xssd[1]); //xssd[1] = 1 x 50
	matrix_multiplication << <1, ws_h_sz[2] >> > (levels[1], ws_w_sz[0], 1, xssd[2], 1, ws_w_sz[1], wssd[1]); //wssd[1] = 50 x 100
	sigmoid_backward << <1, ws_w_sz[1] >> > (xssd[1], levels[1], 1, ws_w_sz[0]);

	matrix_multiplication << <1, ws_h_sz[2] >> > (levels[0], ws_h_sz[0], 1, xssd[1], 1, ws_w_sz[0], wssd[0]); // wssd[0] = 784 x 50

	for (j = 0; j < LEVEL_SIZE; j++) {
		set_weight_changes << < ws_h_sz[j], ws_w_sz[j] >> > (wss_dev[j], wssd[j], ws_h_sz[j], ws_w_sz[j]);
	}

	set_bias_changes << <1, ws_w_sz[0] >> > (bss_dev[0], xssd[1], ws_w_sz[0]);
	set_bias_changes << <1, ws_w_sz[1] >> > (bss_dev[1], xssd[2], ws_w_sz[1]);
	set_bias_changes << <1, ws_w_sz[2] >> > (bss_dev[2], swl, ws_w_sz[2]);
	
	cout << cudaGetErrorString(cudaGetLastError()) << endl;
	
		cout << cudaGetErrorString(cudaGetLastError()) << endl;
		print_matrix << <1, 1 >> > (wsst[1], 5000);
	
	
layer 0 = 1 x 784
w = 784 x 50

layer 1 = 1 x 50
w = 50 x 100

layer 2 = 1 x 100
w = 100 x 10

layer 3 = 1 x 10

bss = new float* [LEVEL_SIZE];
bs_arr_sz = new int[LEVEL_SIZE] { 100, 200, 10 };

wss = new float* [LEVEL_SIZE];
ws_h_sz = new int[LEVEL_SIZE] { 784, 50, 100 };
ws_w_sz = new int[LEVEL_SIZE] { 50, 100, 10 };

h = 784 50 100
w = 50 100 10

0   1  2   3
784 50 100 10










void predict(float* image, int label) {
	int i;

	cudaMemcpy(levels[0], image, level_size[0] * sizeof(float), cudaMemcpyHostToDevice);

	matrix_multiplication << <1, level_size[1] >> > (levels[0], 1, level_size[0], wss_dev[0], level_size[0], level_size[1], levels[1]);
	bias_sigmoid << <1, level_size[1] >> > (levels[1], bss_dev[0]);

	matrix_multiplication << <1, level_size[2] >> > (levels[1], 1, level_size[1], wss_dev[1], level_size[1], level_size[2], levels[2]);
	bias_sigmoid << <1, level_size[2] >> > (levels[2], bss_dev[1]);

	matrix_multiplication << <1, level_size[3] >> > (levels[2], 1, level_size[2], wss_dev[2], level_size[2], level_size[3], levels[3]);
	softmax << <1, 1 >> > (levels[3], output_dev, level_size[3]);
	cudaMemcpy(output, output_dev, level_size[3] * sizeof(float), cudaMemcpyDeviceToHost);

	memset(ans, 0, level_size[3] * sizeof(float));
	ans[label] = 1;

	cee = cross_entropy_error(output, ans, level_size[3]);

	int maxidx = -1;
	float max = -1;
	for (i = 0; i < level_size[3]; i++) {
		if (output[i] > max) {
			max = output[i];
			maxidx = i;
		}
	}

	anstmp = maxidx;
}

void backprop(float* img, int label) {
	int i, j;

	for (i = 0; i < LEARN_COUNT; i++) {
		predict(img, label);
		//cout << cee << endl;
		for (j = 0; j < LEVEL_SIZE; j++) {
			matrix_transpose << <level_size[j], level_size[j + 1] >> > (wss_dev[j], level_size[j], level_size[j + 1], wsst[j]);
		}

		output[label]--;
		cudaMemcpy(xssd[3], output, level_size[3] * sizeof(float), cudaMemcpyHostToDevice);
		output[label]++;

		matrix_multiplication << <1, level_size[2] >> > (xssd[3], 1, level_size[3], wsst[2], 10, level_size[2], xssd[2]); //xssd[2] = 1 x 100		
		matrix_multiplication << <level_size[2], level_size[3] >> > (levels[2], level_size[2], 1, xssd[3], 1, level_size[3], wssd[2]); //wssd[2] = 100 x 10
		sigmoid_backward << <1, level_size[2] >> > (xssd[2], levels[2], 1, level_size[2]);

		matrix_multiplication << <1, level_size[1] >> > (xssd[2], 1, level_size[2], wsst[1], level_size[2], level_size[1], xssd[1]); //xssd[1] = 1 x 50
		matrix_multiplication << <level_size[1], level_size[2] >> > (levels[1], level_size[1], 1, xssd[2], 1, level_size[2], wssd[1]); //wssd[1] = 50 x 100
		sigmoid_backward << <1, level_size[1] >> > (xssd[1], levels[1], 1, level_size[1]);

		matrix_multiplication << <level_size[0], level_size[1] >> > (levels[0], level_size[0], 1, xssd[1], 1, level_size[1], wssd[0]); //wssd[0] = 784 x 50

		for (j = 0; j < LEVEL_SIZE; j++) {
			set_weight_changes << < level_size[j], level_size[j + 1] >> > (wss_dev[j], wssd[j], level_size[j], level_size[j + 1]);
			set_bias_changes << <1, level_size[j + 1] >> > (bss_dev[j], xssd[j + 1], level_size[j + 1]);
		}
	}
}

	float t1[16];
	for (int i = 0; i < 16; i++) {
		t1[i] = i + 1;
	}
	float t2[4];
	for (int i = 0; i < 4; i++) {
		t2[i] = i + 1;
	}
	float* dev1;
	float* dev2;
	float* devr;
	cudaMalloc((void**)&dev1, 16 * sizeof(float));
	cudaMalloc((void**)&dev2, 4 * sizeof(float));
	cudaMalloc((void**)&devr, 9 * sizeof(float));
	cudaMemcpy(dev1, t1, 16 * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(dev2, t2, 4 * sizeof(float), cudaMemcpyHostToDevice);
	cnnFilter << <3, 3 >> > (dev1, 4, dev2, 2, devr);
	print_matrix << <1, 1 >> > (dev1, 16, 4);
	print_matrix << <1, 1 >> > (dev2, 4, 2);
	print_matrix << <1, 1 >> > (devr, 9, 3);
	return 0;
	
	
		//free memory
	for (i = 0; i < LEVEL_SIZE; i++) {
		cudaFree(bss_dev[i]);
		cudaFree(wss_dev[i]);
		cudaFree(wsst[i]);
		cudaFree(wssd[i]);
		cudaFree(level[i]);
		cudaFree(xssd[i]);
	}
	cudaFree(level[3]);
	cudaFree(xssd[3]);

	cudaFree(bss_dev);
	cudaFree(wss_dev);
	cudaFree(wsst);
	cudaFree(wssd);
	cudaFree(level);
	cudaFree(xssd);

	for (i = 0; i < FILTER_COUNT; i++) {
		cudaFree(cnn[i]);
		cudaFree(cnn_w[i]);
		cudaFree(cnn_b[i]);
		cudaFree(cnn_b_w[i]);
		cudaFree(filter[i]);
	}
	cudaFree(cnn);
	cudaFree(cnn_w);
	cudaFree(cnn_b);
	cudaFree(cnn_b_w);
	cudaFree(filter);
	//~free memory
	
	
	
	//#include "cuda_runtime.h"
//#include "device_launch_parameters.h"
//
//#include <iostream>
//#include <stdio.h>
//
//using namespace std;
//
//cudaError_t addWithCuda(int* c, const int* a, const int* b, unsigned int size);
//
//__global__ void addKernel(int* c, const int* a, const int* b)
//{
//    int i = threadIdx.x;
//    c[i] = a[i] + b[i];
//}
//
//int main()
//{
//    const int arraySize = 5;
//    const int a[arraySize] = { 1, 2, 3, 4, 5 };
//    const int b[arraySize] = { 10, 20, 30, 40, 50 };
//    int c[arraySize] = { 0 };
//
//    // Add vectors in parallel.
//    cudaError_t cudaStatus = addWithCuda(c, a, b, arraySize);
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "addWithCuda failed!");
//        return 1;
//    }
//
//    printf("{1,2,3,4,5} + {10,20,30,40,50} = {%d,%d,%d,%d,%d}\n",
//        c[0], c[1], c[2], c[3], c[4]);
//
//    // cudaDeviceReset must be called before exiting in order for profiling and
//    // tracing tools such as Nsight and Visual Profiler to show complete traces.
//    cudaStatus = cudaDeviceReset();
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaDeviceReset failed!");
//        return 1;
//    }
//
//    return 0;
//}
//
//// Helper function for using CUDA to add vectors in parallel.
//cudaError_t addWithCuda(int* c, const int* a, const int* b, unsigned int size)
//{
//    int* dev_a = 0;
//    int* dev_b = 0;
//    int* dev_c = 0;
//    cudaError_t cudaStatus;
//
//    // Choose which GPU to run on, change this on a multi-GPU system.
//    cudaStatus = cudaSetDevice(0);
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaSetDevice failed!  Do you have a CUDA-capable GPU installed?");
//        goto Error;
//    }
//
//    // Allocate GPU buffers for three vectors (two input, one output)    .
//    cudaStatus = cudaMalloc((void**)&dev_c, size * sizeof(int));
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMalloc failed!");
//        goto Error;
//    }
//
//    cudaStatus = cudaMalloc((void**)&dev_a, size * sizeof(int));
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMalloc failed!");
//        goto Error;
//    }
//
//    cudaStatus = cudaMalloc((void**)&dev_b, size * sizeof(int));
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMalloc failed!");
//        goto Error;
//    }
//
//    // Copy input vectors from host memory to GPU buffers.
//    cudaStatus = cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice);
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMemcpy failed!");
//        goto Error;
//    }
//
//    cudaStatus = cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice);
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMemcpy failed!");
//        goto Error;
//    }
//
//    // Launch a kernel on the GPU with one thread for each element.
//    addKernel << <1, size >> > (dev_c, dev_a, dev_b);
//
//    // Check for any errors launching the kernel
//    cudaStatus = cudaGetLastError();
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "addKernel launch failed: %s\n", cudaGetErrorString(cudaStatus));
//        goto Error;
//    }
//
//    // cudaDeviceSynchronize waits for the kernel to finish, and returns
//    // any errors encountered during the launch.
//    cudaStatus = cudaDeviceSynchronize();
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaDeviceSynchronize returned error code %d after launching addKernel!\n", cudaStatus);
//        goto Error;
//    }
//
//    // Copy output vector from GPU buffer to host memory.
//    cudaStatus = cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost);
//    if (cudaStatus != cudaSuccess) {
//        fprintf(stderr, "cudaMemcpy failed!");
//        goto Error;
//    }
//
//Error:
//    cudaFree(dev_c);
//    cudaFree(dev_a);
//    cudaFree(dev_b);
//
//    return cudaStatus;
//}
